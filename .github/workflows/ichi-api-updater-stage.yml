name: Ichi API Updater (Stage)

on:
  push:
    branches:
      - master

jobs:
  stage:
    if: github.event_name == 'push' || (github.event_name == 'pull_request' && github.event.action != 'closed')
    name: build-deploy-stage
    runs-on: ubuntu-latest
    environment:
      name: stage
      url: https://console.aws.amazon.com/lambda/home?region=us-east-1#/functions/managed-ichi-api-updater-stage?tab=code
    env:
      function-name: managed-ichi-api-updater
      env-name: stage
      zip-name: ichi-api-updater-stage
      s3-bucket-name: lambda-ichi-api-updater
      dist-directory: ./dist

    steps:
      - uses: actions/checkout@v2

      - name: Install Node.js
        uses: actions/setup-node@v1
        with:
          node-version: 14.x

      - name: Cache node modules
        uses: actions/cache@v2
        env:
          cache-name: cache-node-modules
        with:
          # npm cache files are stored in `~/.npm` on Linux/macOS
          path: ~/.npm
          key: ${{ runner.os }}-build-${{ env.cache-name }}-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-build-${{ env.cache-name }}-
            ${{ runner.os }}-build-
            ${{ runner.os }}-

      # For testing and building we need all node modules
      - name: npm install
        run: |
          npm i

      - name: Lint
        run: |
          npm run lint

      - name: Test
        run: |
          npm run test

      - name: Build
        run: |
          npm run build

      # For testing and building we need all node modules
      # But for pushing to lambda, since we are using layers, we only want to include
      # the @ichidao/ichi-sdk and put the rest in layers
      # So let's remove and just install production node modules
      - name: Prune non-prod modules
        run: |
          npm prune --production

      - name: Remove all but @ichidao/ichi-sdk
        run: |
          mv node_modules/@ichidao ..
          rm -rf node_modules/*
          mv ../@ichidao node_modules/

      # Copy the node_modules to the dist directory.  If we don't have this then
      # the zip is more efficient and compact but we need to rely on layers, which is elegant
      # however that comes at an added complexity with a race condition with the ichi-sdk.
      - name: Copy node_modules
        run: |
          cp -R node_modules ${{env.dist-directory}}/

      - name: Make artifact directory
        run: mkdir -p ./artifacts

      - name: zip results
        run: |
          zip -r ../artifacts/${{env.zip-name}}.zip *
        working-directory: ${{env.dist-directory}}

      - name: list dir contents
        run: |
          ls -lah

      # Update the old function
      # - name: Deploy function ${{env.function-name}}-${{env.env-name}}
      #   uses: appleboy/lambda-action@v0.1.3
      #   with:
      #     aws_access_key_id: ${{ secrets.AWS_ACCESS_KEY_ID }}
      #     aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      #     aws_region: us-east-1
      #     function_name: ${{env.function-name}}-${{env.env-name}}
      #     zip_file: ./${{env.function-name}}.zip

      - name: Publish Artifacts
        uses: actions/upload-artifact@v1.0.0
        with:
          name: ${{env.zip-name}}
          path: ./artifacts/${{env.zip-name}}.zip

      - name: Push zip to S3
        uses: jakejarvis/s3-sync-action@v0.3.1
        env:
          SOURCE_DIR: ./artifacts
          AWS_REGION: 'us-east-1'
          AWS_S3_BUCKET: ${{env.s3-bucket-name}}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      # Update the new function
      - name: Deploy function ${{env.function-name}}-${{env.env-name}}
        uses: appleboy/lambda-action@master
        with:
          aws_access_key_id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws_region: us-east-1
          function_name: ${{env.function-name}}-${{env.env-name}}
          s3_bucket: ${{env.s3-bucket-name}}
          s3_key: ${{env.zip-name}}.zip
  prod:
    name: build-deploy-prod
    runs-on: ubuntu-latest
    needs: stage
    environment:
      name: prod
      url: https://console.aws.amazon.com/lambda/home?region=us-east-1#/functions/managed-ichi-api-updater-cron-prod?tab=code
    env:
      function-name: managed-ichi-api-updater-cron
      env-name: prod
      zip-name: ichi-api-updater-cron-prod
      dist-directory: ./dist
      s3-bucket-name: lambda-ichi-api-updater-cron

    steps:
      - uses: actions/checkout@v2

      - name: Install Node.js
        uses: actions/setup-node@v1
        with:
          node-version: 14.x

      # - name: Cache node modules
      #   uses: actions/cache@v2
      #   env:
      #     cache-name: cache-node-modules
      #   with:
      #     # npm cache files are stored in `~/.npm` on Linux/macOS
      #     path: ~/.npm
      #     key: ${{ runner.os }}-build-${{ env.cache-name }}-${{ hashFiles('**/package-lock.json') }}
      #     restore-keys: |
      #       ${{ runner.os }}-build-${{ env.cache-name }}-
      #       ${{ runner.os }}-build-
      #       ${{ runner.os }}-

      # For testing and building we need all node modules
      - name: npm install
        run: |
          npm i

      - name: Lint
        run: |
          npm run lint

      - name: Test
        run: |
          npm run test

      - name: Build
        run: |
          npm run build

      # For testing and building we need all node modules
      # But for pushing to lambda, since we are using layers, we only want to include
      # the @ichidao/ichi-sdk and put the rest in layers
      # So let's remove and just install production node modules
      - name: Prune non-prod modules
        run: |
          npm prune --production

      - name: Remove all but @ichidao/ichi-sdk
        run: |
          mv node_modules/@ichidao ..
          rm -rf node_modules/*
          mv ../@ichidao node_modules/

      # Copy the node_modules to the dist directory.  If we don't have this then
      # the zip is more efficient and compact but we need to rely on layers, which is elegant
      # however that comes at an added complexity with a race condition with the ichi-sdk.
      - name: Copy node_modules
        run: |
          cp -R node_modules ${{env.dist-directory}}/

      - name: Make artifact directory
        run: mkdir -p ./artifacts

      - name: zip results
        run: |
          zip -r ../artifacts/${{env.zip-name}}.zip *
        working-directory: ${{env.dist-directory}}

      # Update the old function
      # - name: Deploy function ${{env.function-name}}-${{env.env-name}}
      #   uses: appleboy/lambda-action@v0.1.3
      #   with:
      #     aws_access_key_id: ${{ secrets.AWS_ACCESS_KEY_ID }}
      #     aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      #     aws_region: us-east-1
      #     function_name: ${{env.function-name}}-${{env.env-name}}
      #     zip_file: ./${{env.function-name}}.zip

      - name: Publish Artifacts
        uses: actions/upload-artifact@v1.0.0
        with:
          name: ${{env.zip-name}}
          path: ./artifacts/${{env.zip-name}}.zip

      - name: Push zip to S3
        uses: jakejarvis/s3-sync-action@v0.3.1
        env:
          SOURCE_DIR: ./artifacts
          AWS_REGION: 'us-east-1'
          AWS_S3_BUCKET: ${{env.s3-bucket-name}}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      # Update the new function
      - name: Deploy function ${{env.function-name}}-${{env.env-name}}
        uses: appleboy/lambda-action@master
        with:
          aws_access_key_id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws_region: us-east-1
          function_name: ${{env.function-name}}-${{env.env-name}}
          s3_bucket: ${{env.s3-bucket-name}}
          s3_key: ${{env.zip-name}}.zip
